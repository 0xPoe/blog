---
title: 'TiCDC架构和数据同步链路解析'
layout: post

categories: post
tags:
- Golang
- Go
- TiCDC
- TiDB
---

TiCDC 是 TiDB 生态中的一个数据同步工具，它通过拉取 TiKV 的变更日志实现数据的增量同步。它除了可以将 TiDB 的数据同步至 MySQL 兼容的数据库之外，还提供了同步至 Kafka 的能力，支持 `canal` 和 `arvo` 多种开放消息协议供其他系统订阅数据变更。

## 什么是 CDC？
CDC 的全称为 Change Data Capture，它是指从源数据库捕获数据并且将其同步到其他数据库或者应用程序的过程。它作为一种很常见的数据集成方式被大量的应用在数据仓库中。当然任何的数据库系统都可以构建自己的 CDC，比如 SQL Server 的 CDC。TiCDC 就是专属于 TiDB 的 CDC，它的上游只能是 TiDB，但是它的下游可以是其他 MySQL 兼容的数据库系统，也可以是消息队列。

通过 TiCDC 我们可以实现 TiDB 集群之间的灾备，也可以将 TiDB 的数据集成进入其他数据处理系统。

## TiCDC 的架构
我们知道了 CDC 需要获取变更并将它同步给下游的系统，那对于 TiCDC 来说它就很自然的需要从 TiKV 拉取变更，因为 TiDB 集群写入的每一条数据最终都会被持久化到 TiKV 上。下面我们就从架构上来看一看 TiCDC 如何将数据从 TiKV 拉取并同步到下游系统中。

[![](http://www.plantuml.com/plantuml/png/VLB1Ze8m5Bpp5I_UTGF7FHYpU5Epx6BsOZnKUIe1MrCWcyt6Vz--8c-RWfnetqndXdOMLIrqtLpBu2QEXJWZJBRvwci2lm70-JE9OGexca2yZFV1FGYaoWpf_LkYRbcxz7Z1h2bHxsctNAxJN1QqPaapcu2em7n3UyRmh08TlOgqLjhmzWvWc4bJaYPCftFOKHJ2x_yH4gsEM5MgYy7xZMfaJMdSuLYco0gux85S38vaS-JZYv1dF25cOPlFmRRYK688INx3CfVOuUHXTKDFs4AfqhM1U6z5wAyUe_k0H_JS8thk4VKz8lPeNo0JjJY8olXiVjAFzSjAd0hnU0SxiPV_fbM1shQ6Qq6kpF6c7PzgGXEdJ4DrWTbitg_BApGL1kx3-wv367lpFPDwhrIiprSrJdDVoMMojq-BHcbz6o9JWvdX5CZfJBlYkTiThmzS0LvvHmoqG9arr_8F)](https://www.plantuml.com/plantuml/uml/VLB1Rkem4BpxArRSuIavlWD23JT0JHlK2-9Wo09HWesSM5LLyU-r5p3M0Zd5tXdFJEoPj9qqdJqsGfpajfPxXC6ocdqDu5S0x3_p38QmyXF8fjbQd8LGkdIazs-5vi9Q5Ti3bhP1i_QxwNHULAhswo3fPWEGBRXlGcSSZnJyqQCiEcqSRnq1ZfdRncl2S3Y6bO_YyVCzGcxq5jjMtsA4_K9RrL6QQDYNAIM1YCroCV1rjaW-EqYrnnrYcLpoHTXIRXfC8AzEs5GARxZt8Ds42HDKQDCvAEn9nF_LTNH-uf6-zaXVUwIF7kdTWrwWb9tSoDRvB7wAZ_c_cTpLyleEDA7BVpEwHaEj2RNmhZSEcmO-rOGceKpFwWAZqVYnBl_1jYYYf-Ik36FUuPv9dPSgw8UhwgV5hqHCxirfQI-Dsn2P6XmOKO6Ypj3gFe-xm_eGAX1Mx8Y39gXAUsp-0000)

一个 TiCDC 的节点由上图中的几个组件组成：
- Owner: 一个 TiCDC 集群中的某个节点会被选举成为 Owner，它会负责处理任务的调度和 DDL 事件的处理。
- Processor: 其他非 Owner 节点则会启动 Processor 进程来处理 Owner 调度过来的同步任务，它主要负责处理 DML 事件。

> 注意：Owner 节点也会启动 Processor 进程来处理同步任务，但是整个集群中有且仅有一个 Owner。

另外我们注意到，在 TiKV 系统中也存在一个叫做 TiKV CDC 的组件，它就是数据同步的起点，所有的行变更都是由 TiKV 的该组件通过 gRPC 流推送给 TiCDC 节点。

我们先来看一看 Owner 组件的主要职责：
1. Owner 会启动 TiCDC 中的 DDL Puller 向 TiKV 拉取 DDL 的变更，并且对收到的变更数据进行编码，将其转化为 DDL SQL 语句然后通过 DDLSink 写入下游系统。
2. Owner 会通过 scheduler 组件向其他节点发送命令，让其启动 Processor 进程开始同步数据。

当其他节点收到来自 Owner 的同步命令之后，它们就会启动上图所示的 Processor 进程：
1. 每个 Processor 会负责同步一个任务，我们在 TiCDC 中把这些任务称为 Changefeed。
2. 每个任务中可能会根据配置同步多张表，Owner 会根据每个节点的负载将一个 Changefeed 中的表平均的分配到多个节点。
3. 当节点收到命令之后，会启动 Processor 进程，每个 Processor 会根据收到的任务详情启动 Table Pipeline，它作为一个流水线会负责从 TiKV 拉取数据、排序数据、组装数据和写入数据到下游。

根据上述的架构我们知道 TiCDC 同步数据的核心流程是 Table Pipeline，那我们就来看一看一条 SQL 被执行之后，如何从 TiKV 被捕获并同步至下游。

## 数据同步链路
我们可以把 Table Pipeline 细化成四个部分：

[![](https://mermaid.ink/img/pako:eNo1jcsKgzAQRX8lzMqA_kAWXbW7FkrdZjOYsYbmIXGCFPHfG63OYu7lcOAu0EVDoKB3ce4GTCzuLx1EuTE7R6mqnntKKZrmIqaYeIPtngf0MYedPv7ldG34FLN8KaEGT8mjNWVr2QY08ECeNKhSDfWYHWvQYS1qHg0y3YzlmED16CaqATPH9hs6UJwyndLV4juhP6z1B1W3RMs)](https://mermaid.live/edit#pako:eNo1jcsKgzAQRX8lzMqA_kAWXbW7FkrdZjOYsYbmIXGCFPHfG63OYu7lcOAu0EVDoKB3ce4GTCzuLx1EuTE7R6mqnntKKZrmIqaYeIPtngf0MYedPv7ldG34FLN8KaEGT8mjNWVr2QY08ECeNKhSDfWYHWvQYS1qHg0y3YzlmED16CaqATPH9hs6UJwyndLV4juhP6z1B1W3RMs)

- Puller: 负责与 TiKV CDC 组件建立 gRPC 连接并拉取数据
- Sorter: 负责对拉取到的乱序数据进行排序，让其按照事务提交时间进行排序
- Mounter: 根据事务提交时的表结构信息解析和填充行变更，将变更转化为 TiCDC 能直接处理的数据结构
- Sink: 将 Mounter 处理过后的数据进行编码，转化为 SQL 语句或者 Kafka 消息写入下游

### 一个例子
假设我们现在建立如下表结构：
```sql
CREATE TABLE TEST(
   NAME VARCHAR (20)     NOT NULL,
   AGE  INT              NOT NULL,
   PRIMARY KEY (NAME)
);

+-------+-------------+------+------+---------+-------+
| Field | Type        | Null | Key  | Default | Extra |
+-------+-------------+------+------+---------+-------+
| NAME  | varchar(20) | NO   | PRI  | NULL    |       |
| AGE   | int(11)     | NO   |      | NULL    |       |
+-------+-------------+------+------+---------+-------+
```

此时我们在 TiDB 先后执行这两条 DML：
```sql
INSERT INTO TEST (NAME,AGE)
VALUES ('Jack',20);

UPDATE TEST
SET AGE = 25
WHERE NAME = 'Jack';
```
下面我们就来看一看这两条 DML 会通过什么样的链路写入下游。
### 数据写入到 TiKV

### Puller 从 TiKV 拉取

### Sorter 进行排序

### Mounter 进行解析

### Sink 进行下发

## 如何监测数据同步进度？

## 术语表

## 参考链接
